{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=m3_w3_t1, master=local[*]) created by __init__ at <ipython-input-2-861f245ef866>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-861f245ef866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"m3_w3_t1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 275\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=m3_w3_t1, master=local[*]) created by __init__ at <ipython-input-2-861f245ef866>:1 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"m3_w3_t1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+\n",
      "|Elevation|Aspect|Slope|Horizontal_Distance_To_Hydrology|Vertical_Distance_To_Hydrology|Horizontal_Distance_To_Roadways|Hillshade_9am|Hillshade_Noon|Hillshade_3pm|Horizontal_Distance_To_Fire_Points|Wild_Type|           Soil_Type|Target|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+\n",
      "|     3122|   266|   10|                             433|                            75|                           3069|          195|           245|          188|                               451| Comanche|Catamount family ...|     1|\n",
      "|     3018|   308|   15|                              60|                            14|                           5359|          177|           229|          192|                              4546|    Rawah|Como - Legault fa...|     1|\n",
      "|     3146|   151|   12|                             541|                            -2|                           5887|          236|           240|          132|                              1371|    Rawah|Como - Legault fa...|     2|\n",
      "|     2980|   163|    6|                             553|                            21|                           3538|          226|           242|          149|                              1087|    Rawah|Como - Legault fa...|     2|\n",
      "|     2972|   187|   16|                             255|                           109|                           6390|          220|           250|          158|                              4119|    Rawah|Como family - Roc...|     2|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf = spark.read.option(\"inferSchema\", \"true\").csv(\"/data/covertype2/train.csv\", header=True)\n",
    "trainDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+-------------+-------------+\n",
      "|Elevation|Aspect|Slope|Horizontal_Distance_To_Hydrology|Vertical_Distance_To_Hydrology|Horizontal_Distance_To_Roadways|Hillshade_9am|Hillshade_Noon|Hillshade_3pm|Horizontal_Distance_To_Fire_Points|Wild_Type|           Soil_Type|Target|Wild_Type_Ind|Soil_Type_Ind|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+-------------+-------------+\n",
      "|     3122|   266|   10|                             433|                            75|                           3069|          195|           245|          188|                               451| Comanche|Catamount family ...|     1|          1.0|          2.0|\n",
      "|     3018|   308|   15|                              60|                            14|                           5359|          177|           229|          192|                              4546|    Rawah|Como - Legault fa...|     1|          0.0|          0.0|\n",
      "|     3146|   151|   12|                             541|                            -2|                           5887|          236|           240|          132|                              1371|    Rawah|Como - Legault fa...|     2|          0.0|          0.0|\n",
      "|     2980|   163|    6|                             553|                            21|                           3538|          226|           242|          149|                              1087|    Rawah|Como - Legault fa...|     2|          0.0|          0.0|\n",
      "|     2972|   187|   16|                             255|                           109|                           6390|          220|           250|          158|                              4119|    Rawah|Como family - Roc...|     2|          0.0|          6.0|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+---------+--------------------+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wildTypeIndexer = StringIndexer(inputCol=\"Wild_Type\", outputCol=\"Wild_Type_Ind\")\n",
    "wtModel = wildTypeIndexer.fit(trainDf)\n",
    "trainDf2 = wtModel.transform(trainDf)\n",
    "\n",
    "soilTypeIndexer = StringIndexer(inputCol=\"Soil_Type\", outputCol=\"Soil_Type_Ind\")\n",
    "stModel = soilTypeIndexer.fit(trainDf2)\n",
    "trainDfInd = stModel.transform(trainDf2)\n",
    "\n",
    "trainDfInd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[3122.0,266.0,10....|    1|\n",
      "|[3018.0,308.0,15....|    1|\n",
      "|[3146.0,151.0,12....|    2|\n",
      "|[2980.0,163.0,6.0...|    2|\n",
      "|[2972.0,187.0,16....|    2|\n",
      "|[2768.0,17.0,13.0...|    2|\n",
      "|[2948.0,319.0,9.0...|    1|\n",
      "|[2127.0,320.0,31....|    6|\n",
      "|[2968.0,322.0,19....|    1|\n",
      "|[2983.0,295.0,10....|    1|\n",
      "|[2947.0,54.0,22.0...|    2|\n",
      "|[2987.0,130.0,16....|    2|\n",
      "|[2748.0,8.0,14.0,...|    2|\n",
      "|[3330.0,81.0,18.0...|    7|\n",
      "|[2944.0,12.0,13.0...|    2|\n",
      "|[3381.0,203.0,10....|    7|\n",
      "|[3083.0,199.0,13....|    1|\n",
      "|[3451.0,279.0,17....|    7|\n",
      "|[3202.0,51.0,19.0...|    1|\n",
      "|[2900.0,221.0,14....|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "featureAssembler = VectorAssembler(\n",
    "    inputCols=[\"Elevation\",\"Aspect\",\"Slope\",\"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\n",
    "               \"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\n",
    "               \"Horizontal_Distance_To_Fire_Points\", \"Wild_Type_Ind\", \"Soil_Type_Ind\"], outputCol=\"features\")\n",
    "\n",
    "data = featureAssembler.transform(trainDfInd).select(col(\"features\"),col(\"target\").alias(\"label\"))\n",
    "\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(labelCol=\"label\", maxBins=45, maxDepth=9)\n",
    "model = randomForest.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|    2|       1.0|\n",
      "|    3|       3.0|\n",
      "|    3|       3.0|\n",
      "|    3|       3.0|\n",
      "|    6|       6.0|\n",
      "|    6|       6.0|\n",
      "|    3|       3.0|\n",
      "|    6|       6.0|\n",
      "|    3|       3.0|\n",
      "|    6|       3.0|\n",
      "|    6|       6.0|\n",
      "|    6|       3.0|\n",
      "|    6|       3.0|\n",
      "|    6|       3.0|\n",
      "|    3|       3.0|\n",
      "|    6|       6.0|\n",
      "|    6|       6.0|\n",
      "|    6|       6.0|\n",
      "|    3|       4.0|\n",
      "|    3|       3.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(testData)\n",
    "\n",
    "prediction.select(\"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(12, {0: 0.4733, 1: 0.0136, 2: 0.0102, 3: 0.0266, 4: 0.0188, 5: 0.0585, 6: 0.0116, 7: 0.0225, 8: 0.0086, 9: 0.0466, 10: 0.1414, 11: 0.1684})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767912571132954"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
